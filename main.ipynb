{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff7ad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5py\n",
      "  Downloading h5py-3.14.0-cp311-cp311-win_amd64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\ercan\\miniconda3\\envs\\opt_env\\lib\\site-packages (from h5py) (1.26.4)\n",
      "Downloading h5py-3.14.0-cp311-cp311-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.8/2.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.3/2.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.1/2.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.6/2.9 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 2.9 MB/s eta 0:00:00\n",
      "Installing collected packages: h5py\n",
      "Successfully installed h5py-3.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e333f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ana gruplar: ['fanet_topo_dataset']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to get group info (addr overflow, addr = 14535688, size = 544, eoa = 2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAna gruplar:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(hf.keys()))  \u001b[38;5;66;03m# -> ['fanet_topo_dataset']\u001b[39;00m\n\u001b[32m      7\u001b[39m grp = hf[\u001b[33m'\u001b[39m\u001b[33mfanet_topo_dataset\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m snapshots = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mToplam snapshot:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(snapshots))\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mÖrnek snapshot isimleri:\u001b[39m\u001b[33m\"\u001b[39m, snapshots[:\u001b[32m5\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen _collections_abc>:816\u001b[39m, in \u001b[36m__len__\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ercan\\miniconda3\\envs\\opt_env\\Lib\\site-packages\\h5py\\_hl\\group.py:497\u001b[39m, in \u001b[36mGroup.__len__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;129m@with_phil\u001b[39m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    496\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" Number of members attached to this group \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_num_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5g.pyx:346\u001b[39m, in \u001b[36mh5py.h5g.GroupID.get_num_objs\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unable to get group info (addr overflow, addr = 14535688, size = 544, eoa = 2048)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# 1.1 Dosyayı aç ve ana grupları listele\n",
    "hf = h5py.File('fanet_topo_dataset.h5', 'r')\n",
    "print(\"Ana gruplar:\", list(hf.keys()))  # -> ['fanet_topo_dataset']\n",
    "\n",
    "grp = hf['fanet_topo_dataset']\n",
    "snapshots = list(grp.keys())\n",
    "print(\"Toplam snapshot:\", len(snapshots))\n",
    "print(\"Örnek snapshot isimleri:\", snapshots[:5])\n",
    "\n",
    "# 1.2 İlk snapshot'ın içeriğini göster\n",
    "snap0 = grp[snapshots[0]]\n",
    "print(\"positions shape:\", snap0['positions'].shape)\n",
    "print(\"persistence_image length:\", snap0['persistence_image'].shape)\n",
    "print(\"Attrs:\")\n",
    "for k, v in snap0.attrs.items():\n",
    "    print(f\"  {k} = {v}\")\n",
    "\n",
    "hf.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac5396a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (350000, 400) (75000, 400) (75000, 400)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 2.1 Tüm snapshot’lardaki verileri oku\n",
    "hf = h5py.File('fanet_topo_dataset.h5', 'r')\n",
    "grp = hf['fanet_topo_dataset']\n",
    "\n",
    "X_img = []\n",
    "X_feat = []\n",
    "y = []\n",
    "\n",
    "for name in grp:\n",
    "    s = grp[name]\n",
    "    # persistence image\n",
    "    img = s['persistence_image'][:]\n",
    "    X_img.append(img)\n",
    "    # sayısal öznitelikler\n",
    "    bf = s.attrs['beta0_fixed']\n",
    "    ba = s.attrs['beta0_adaptive']\n",
    "    rc = s.attrs['r_c_adaptive']\n",
    "    X_feat.append([bf, ba, rc])\n",
    "    # etiket (örneğin RWP vs GM sınıflandırması için)\n",
    "    model = s.attrs['model'].decode() if isinstance(s.attrs['model'], bytes) else s.attrs['model']\n",
    "    y.append(0 if model=='RWP' else 1)\n",
    "\n",
    "hf.close()\n",
    "\n",
    "X_img = np.vstack(X_img)        # (num_snapshots, pixels* pixels)\n",
    "X_feat = np.array(X_feat)       # (num_snapshots, 3)\n",
    "y = np.array(y)                 # (num_snapshots,)\n",
    "\n",
    "# 2.2 Normalize / standardize\n",
    "img_scaler = MinMaxScaler()\n",
    "X_img = img_scaler.fit_transform(X_img)\n",
    "\n",
    "feat_scaler = StandardScaler()\n",
    "X_feat = feat_scaler.fit_transform(X_feat)\n",
    "\n",
    "# 2.3 Train/Val/Test böl\n",
    "X_img_tr, X_img_temp, X_feat_tr, X_feat_temp, y_tr, y_temp = train_test_split(\n",
    "    X_img, X_feat, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "X_img_val, X_img_te, X_feat_val, X_feat_te, y_val, y_te = train_test_split(\n",
    "    X_img_temp, X_feat_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(\"Shapes:\", X_img_tr.shape, X_img_val.shape, X_img_te.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ce71578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FANETDataset(Dataset):\n",
    "    def __init__(self, X_img, X_feat, y):\n",
    "        self.X_img = torch.from_numpy(X_img).float()\n",
    "        self.X_feat = torch.from_numpy(X_feat).float()\n",
    "        self.y = torch.from_numpy(y).float().unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'img': self.X_img[idx],      # persistence image vector\n",
    "            'feat': self.X_feat[idx],    # numeric features\n",
    "            'y': self.y[idx]             # label\n",
    "        }\n",
    "\n",
    "# Dataset objeleri\n",
    "train_ds = FANETDataset(X_img_tr, X_feat_tr, y_tr)\n",
    "val_ds   = FANETDataset(X_img_val, X_feat_val, y_val)\n",
    "test_ds  = FANETDataset(X_img_te, X_feat_te, y_te)\n",
    "\n",
    "# DataLoader’lar\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b161619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BaselineMLP(nn.Module):\n",
    "    def __init__(self, img_dim, feat_dim, hidden=64):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(img_dim + feat_dim, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, img, feat):\n",
    "        x = torch.cat([img, feat], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968138e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "class FANET_TopoGNN(nn.Module):\n",
    "    def __init__(self, img_dim, feat_dim, hidden=64, gc_hidden=32, fusion_dim=128):\n",
    "        super().__init__()\n",
    "        # (a) GCN structural encoder\n",
    "        self.conv1 = pyg_nn.GCNConv(2, gc_hidden)\n",
    "        self.conv2 = pyg_nn.GCNConv(gc_hidden, gc_hidden)\n",
    "        # (b) PI encoder\n",
    "        self.pi_mlp = nn.Sequential(\n",
    "            nn.Linear(img_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden)\n",
    "        )\n",
    "        # (c) Gated fusion\n",
    "        self.proj_struct = nn.Linear(gc_hidden, fusion_dim)\n",
    "        self.proj_pi     = nn.Linear(hidden, fusion_dim)\n",
    "        self.proj_gate   = nn.Linear(fusion_dim*2, fusion_dim)\n",
    "        # (d) Regression head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data, img, feat):\n",
    "        # --- structural: GCN on input graph in data ---\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        h = F.relu(self.conv1(x, edge_index))\n",
    "        h = F.relu(self.conv2(h, edge_index))\n",
    "        z_struct = pyg_nn.global_mean_pool(h, data.batch)  # (batch, gc_hidden)\n",
    "\n",
    "        # --- topological: PI mlp ---\n",
    "        z_pi = self.pi_mlp(img)  # (batch, hidden)\n",
    "\n",
    "        # --- gated fusion ---\n",
    "        s = self.proj_struct(z_struct)\n",
    "        p = self.proj_pi(z_pi)\n",
    "        gate = torch.sigmoid(self.proj_gate(torch.cat([s,p], dim=1)))\n",
    "        z_f = gate * s + (1-gate) * p\n",
    "\n",
    "        # --- regression ---\n",
    "        return self.head(z_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b97974",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error, r2_score\n\u001b[0;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m FANET_TopoGNN(img_dim\u001b[38;5;241m=\u001b[39m\u001b[43mX_img\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], feat_dim\u001b[38;5;241m=\u001b[39mX_feat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m)\n\u001b[0;32m      7\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_img' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FANET_TopoGNN(img_dim=X_img.shape[1], feat_dim=X_feat.shape[1]).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    # --- train ---\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        img = batch['img'].to(device)\n",
    "        feat= batch['feat'].to(device)\n",
    "        y   = batch['y'].to(device)\n",
    "        # dummy graph data; burayı gerçek edge_index ile değiştirin\n",
    "        data = Data(x=torch.randn(len(y),2).to(device),\n",
    "                    edge_index=torch.empty((2,0),dtype=torch.long).to(device),\n",
    "                    batch=torch.arange(len(y), device=device))\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(data, img, feat)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(y)\n",
    "    total_loss /= len(train_ds)\n",
    "\n",
    "    # --- validate ---\n",
    "    model.eval()\n",
    "    val_preds, val_trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            img = batch['img'].to(device)\n",
    "            feat= batch['feat'].to(device)\n",
    "            y   = batch['y'].to(device)\n",
    "            data = Data(x=torch.randn(len(y),2).to(device),\n",
    "                        edge_index=torch.empty((2,0),dtype=torch.long).to(device),\n",
    "                        batch=torch.arange(len(y), device=device))\n",
    "            y_hat = model(data, img, feat)\n",
    "            val_preds.append(y_hat.cpu().numpy())\n",
    "            val_trues.append(y.cpu().numpy())\n",
    "    val_preds = np.vstack(val_preds)\n",
    "    val_trues = np.vstack(val_trues)\n",
    "    val_loss = mean_squared_error(val_trues, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Train MSE={total_loss:.4f}, Val MSE={val_loss:.4f}\")\n",
    "    # early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
